---
title: "Homework 2 - P8105"
author: "Tim Hauser (th2899)"
date: 2022-10-05
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

## Problem 1

In the following piped code I'm going to 1. import the NYC Transit data, 2. do some basic cleaning, 3. only select certain columns and re-order the columns into a specific order (line, station name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance), and 4. convert the entry variable from character to a logical variable:

```{r data, warning = FALSE}
nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = if_else(entry == "YES", TRUE, FALSE))
```

To gain an overview of the dataset and the variables it contains:

```{r}
skimr::skim(nyc_transit_df)
```

The data cleaning steps are described above. We are left with 19 variables: line name (character, station name (character), one column each for the first seven routes being served by that station (character), whether there is a vending machine (character since yes/no), the entrance type  (character), whether it's an entry vs. exit (logical), whether it meets ADA compliance (logical), one column each for the latitude and logitude parameters (numeric) and  meets one column each for the eight to eleventh route being served by that station (numeric). After the cleaning, we are left with `r nrow(nyc_transit_df)` rows and `r ncol(nyc_transit_df)` columns.

The dataset is not clean in many ways. First and most importantly, as it is right now it contains many duplicate rows, that is because we excluded many of the columns that would have made these rows distinct. Second, the variable types for routes 8-11 are registered as numeric (simply because they only contain metro lines that are numbers), even though they should be character variables. Third, the vending variables is a character variable but should probably be transformed into logical one. Fourth, the way the routes are displayed seems very clumsy to me - instead of first to eleventh route, one could think of having one column per metro line (e.g., R, N, etc.,) and then a logical variable (TRUE / FALSE) whether that specific line is served or not.


Checking how many distinct stations there are:

```{r}
nyc_transit_distinct_df = distinct(nyc_transit_df, station_name, line, .keep_all = TRUE)
```

There are `r nrow(nyc_transit_distinct_df)` distinct stations.


Double checking above solution with a different approach (that I am more used to from Excel):

```{r}
nyc_transit_combined_df = nyc_transit_df %>% unite(combined, c(station_name, line), sep = " ", remove = FALSE)

nyc_transit_combined_distinct_df = distinct(nyc_transit_combined_df, combined, .keep_all = TRUE)
```

It also yields `r nrow(nyc_transit_combined_distinct_df)` distinct stations.


Filtering among the newly created dataframe of distinct stations by only ADA compliant stations:

```{r}
nrow(filter(nyc_transit_distinct_df, ada == TRUE))
```

There are `r nrow(filter(nyc_transit_distinct_df, ada == TRUE))` distinct stations that are ADA compliant.


To check what proportion of station entrances / exits without vending allow entrance we go back to the old dataframe:

Total number of entrances / exits without vending: `r nrow(filter(nyc_transit_df, vending == "NO"))`

Total number of entrances / exits without vending that allow entry: `r nrow(filter(nyc_transit_df, vending == "NO", entry == TRUE))`

Hence, the proportion of station entrances / exits without vending that allow entrance is `r nrow(filter(nyc_transit_df, vending == "NO", entry == TRUE)) / nrow(filter(nyc_transit_df, vending == "NO"))`


In the following we first transform route 8 - 11 from numeric to character variables. Then we use pivot_longer to combine all route columns into route number and route name. Then we drop all rows that contain NA in the route name column. Lastly, we mutate route number variable to drop the repeated route and instead just show a number:

```{r}
nyc_transit_distinct_tidy_df = 
  transform(nyc_transit_distinct_df,
            route8 = as.character(route8), 
            route9 = as.character(route9), 
            route10 = as.character(route10), 
            route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
    ) %>% 
  drop_na(route_name) %>% 
  mutate(route_number = str_sub(route_number, 6, -1))
```

Now we filter this dataframe to only show stations that serve the A train and of this subset those that are ADA compliant:

```{r}
nrow(filter(nyc_transit_distinct_tidy_df, route_name == "A"))
nrow(filter(nyc_transit_distinct_tidy_df, route_name == "A", ada == TRUE))
```

There are `r nrow(filter(nyc_transit_distinct_tidy_df, route_name == "A"))` stations serving the A train.

Of these stations `r nrow(filter(nyc_transit_distinct_tidy_df, route_name == "A", ada == TRUE))` are ADA compliant.


## Problem 2

The following code loads the data from the Excel into a dataframe and specifies the sheet in the Excel file and omits non-data entries. By applying clean_names I ensure the use of reasonable variable names. Next I omit rows that do not include dumpster-specific data (i.e., the last row) and round the number of sports balls to the nearest integer and convert the result to an integer variable:

```{r}
mr_trash = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N550") %>%
  mutate(trash_wheel = "mister") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, 0)))
```

I repeat the same process for the Professor Trash Wheel, except that this dataset does not contain a sport ball column, and that I transform the year variable from numeric to character to match the mister_trash dataset:

```{r}
professor_trash = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M91") %>%
  mutate(trash_wheel = "professor") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(year = as.character(year))
```

Then I combine the two datasets:

```{r}
combined_trash =
  bind_rows(mr_trash, professor_trash)
```

There are `r nrow(combined_trash)` observations in the combined dataset.

A list of all (key) variables `r names(combined_trash)`

The total weight of trash collected by Professor Trash Wheel is `r sum(select(filter(combined_trash, trash_wheel == "professor"), weight_tons))` tons.

The total number of sports balls collected by Mr. Trash Wheel in 2020 is `r sum(select(filter(combined_trash, trash_wheel == "mister", year == "2020"), sports_balls))`.

## Problem 3

First, I clean the data in pols-month.csv: use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable:

```{r}
pols_month = 
  read_csv("./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month","day")) %>%
  mutate(month = as.integer(month),
         month = month.name[month],
         year = as.integer(year)) %>% 
  mutate(president = if_else(prez_gop == 0, "dem", "gop")) %>%
  select(-prez_dem, -prez_gop, -day)
```


Second, I clean the data in snp.csv using a similar process to the above. For consistency across datasets, I arranged according to year and month, and organized so that year and month are the leading columns:

```{r}
snp = 
  read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  separate(date, into = c("year", "month","day")) %>%
  mutate(
    year = as.integer(year),
    year = ifelse(year > 2050, year - 100, year)) %>%
## Note: somehow the lubridate function converted all years older than 1959 (i.e., 58 or lower) into future dates (i.e., 2058) instead of past datest (i.e., 1958) - this formula fixed it
  mutate(month = as.integer(month),
         month = month.name[month]) %>%
  select(-day) %>% 
  relocate(year, month) %>%
  arrange(year, month)
```


Third, I tidy the unemployment data by switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values:

```{r}
unemployment = 
  read_csv("./data/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  janitor::clean_names() %>%
  mutate(
    month = month.name[match(month,month.abb)],
    year = as.integer(year))
```

Lastly, I join the datasets by merging snp into pols, and merging unemployment into the result.

```{r}
combined_p3 = 
  left_join(pols_month, snp) %>% 
  left_join(unemployment)
```

Quickly double-checking whether the piping works with join functions as expected:

```{r}
combined_p3_2 = left_join(pols_month, snp)
combined_p3_2 = left_join(combined_p3_2, unemployment)
```


Pols_month is a `r nrow(pols_month)` rows by `r ncol(pols_month)` columns dataset with a range of years of `r range(pull(pols_month, year))` and which contains the following key variables `r names(pols_month)` . Snp is a `r nrow(snp)` rows by `r ncol(snp)` columns dataset with a range of years of `r range(pull(snp, year))` and which contains the following key variables `r names(snp)`. Unemployment is a `r nrow(unemployment)` rows by `r ncol(unemployment)` columns dataset with a range of years of `r range(pull(unemployment, year))` and which contains the following key variables `r names(unemployment)`. By combining all three datasets into a single one called combined_p3, which is a `r nrow(combined_p3)` rows by `r ncol(combined_p3)` columns dataset with a range of years of `r range(pull(combined_p3, year))` and which contains the following key variables `r names(combined_p3)`.
