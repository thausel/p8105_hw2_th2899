Homework 2 - P8105
================
Tim Hauser (th2899)
2022-10-05

## Problem 1

In the following piped code I’m going to 1. import the NYC Transit data,
2. do some basic cleaning, 3. only select certain columns and re-order
the columns into a specific order (line, station name, station latitude
/ longitude, routes served, entry, vending, entrance type, and ADA
compliance), and 4. convert the entry variable from character to a
logical variable:

``` r
nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = if_else(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

To gain an overview of the dataset and the variables it contains:

``` r
skimr::skim(nyc_transit_df)
```

|                                                  |                |
|:-------------------------------------------------|:---------------|
| Name                                             | nyc_transit_df |
| Number of rows                                   | 1868           |
| Number of columns                                | 19             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                |
| Column type frequency:                           |                |
| character                                        | 11             |
| logical                                          | 2              |
| numeric                                          | 6              |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                |
| Group variables                                  | None           |

Data summary

**Variable type: character**

| skim_variable | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:--------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| line          |         0 |          1.00 |   5 |  17 |     0 |       36 |          0 |
| station_name  |         0 |          1.00 |   4 |  39 |     0 |      356 |          0 |
| route1        |         0 |          1.00 |   1 |   2 |     0 |       24 |          0 |
| route2        |       848 |          0.55 |   1 |   2 |     0 |       20 |          0 |
| route3        |      1374 |          0.26 |   1 |   2 |     0 |       18 |          0 |
| route4        |      1547 |          0.17 |   1 |   1 |     0 |       13 |          0 |
| route5        |      1630 |          0.13 |   1 |   1 |     0 |       12 |          0 |
| route6        |      1741 |          0.07 |   1 |   1 |     0 |        7 |          0 |
| route7        |      1788 |          0.04 |   1 |   2 |     0 |        7 |          0 |
| vending       |         0 |          1.00 |   2 |   3 |     0 |        2 |          0 |
| entrance_type |         0 |          1.00 |   4 |   9 |     0 |        7 |          0 |

**Variable type: logical**

| skim_variable | n_missing | complete_rate | mean | count               |
|:--------------|----------:|--------------:|-----:|:--------------------|
| entry         |         0 |             1 | 0.94 | TRU: 1753, FAL: 115 |
| ada           |         0 |             1 | 0.25 | FAL: 1400, TRU: 468 |

**Variable type: numeric**

| skim_variable     | n_missing | complete_rate |   mean |   sd |     p0 |    p25 |    p50 |    p75 |   p100 | hist  |
|:------------------|----------:|--------------:|-------:|-----:|-------:|-------:|-------:|-------:|-------:|:------|
| station_latitude  |         0 |          1.00 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| station_longitude |         0 |          1.00 | -73.94 | 0.06 | -74.03 | -73.99 | -73.96 | -73.91 | -73.76 | ▇▆▃▂▁ |
| route8            |      1820 |          0.03 |   2.98 | 1.94 |   1.00 |   1.00 |   4.00 |   5.00 |   5.00 | ▇▁▁▂▇ |
| route9            |      1840 |          0.01 |   2.54 | 1.17 |   2.00 |   2.00 |   2.00 |   2.00 |   5.00 | ▇▁▁▁▂ |
| route10           |      1845 |          0.01 |   3.00 | 0.00 |   3.00 |   3.00 |   3.00 |   3.00 |   3.00 | ▁▁▇▁▁ |
| route11           |      1845 |          0.01 |   7.00 | 0.00 |   7.00 |   7.00 |   7.00 |   7.00 |   7.00 | ▁▁▇▁▁ |

The data cleaning steps are described above. We are left with 19
variables: line name (character, station name (character), one column
each for the first seven routes being served by that station
(character), whether there is a vending machine (character since
yes/no), the entrance type (character), whether it’s an entry vs. exit
(logical), whether it meets ADA compliance (logical), one column each
for the latitude and logitude parameters (numeric) and meets one column
each for the eight to eleventh route being served by that station
(numeric). After the cleaning, we are left with 1868 rows and 19
columns.

The dataset is not clean in many ways. First and most importantly, as it
is right now it contains many duplicate rows, that is because we
excluded many of the columns that would have made these rows distinct.
Second, the variable types for routes 8-11 are registered as numeric
(simply because they only contain metro lines that are numbers), even
though they should be character variables. Third, the vending variables
is a character variable but should probably be transformed into logical
one. Fourth, the way the routes are displayed seems very clumsy to me -
instead of first to eleventh route, one could think of having one column
per metro line (e.g., R, N, etc.,) and then a logical variable (TRUE /
FALSE) whether that specific line is served or not.

Checking how many distinct stations there are:

``` r
nyc_transit_distinct_df = distinct(nyc_transit_df, station_name, line, .keep_all = TRUE)
```

There are 465 distinct stations.

Double checking above solution with a different approach (that I am more
used to from Excel):

``` r
nyc_transit_combined_df = nyc_transit_df %>% unite(combined, c(station_name, line), sep = " ", remove = FALSE)

nyc_transit_combined_distinct_df = distinct(nyc_transit_combined_df, combined, .keep_all = TRUE)
```

It also yields 465 distinct stations.

Filtering among the newly created dataframe of distinct stations by only
ADA compliant stations:

``` r
nrow(filter(nyc_transit_distinct_df, ada == TRUE))
```

    ## [1] 84

There are 84 distinct stations that are ADA compliant.

To check what proportion of station entrances / exits without vending
allow entrance we go back to the old dataframe:

Total number of entrances / exits without vending: 183

Total number of entrances / exits without vending that allow entry: 69

Hence, the proportion of station entrances / exits without vending that
allow entrance is 0.3770492

In the following we first transform route 8 - 11 from numeric to
character variables. Then we use pivot_longer to combine all route
columns into route number and route name. Then we drop all rows that
contain NA in the route name column. Lastly, we mutate route number
variable to drop the repeated route and instead just show a number:

``` r
nyc_transit_distinct_tidy_df = 
  transform(nyc_transit_distinct_df,
            route8 = as.character(route8), 
            route9 = as.character(route9), 
            route10 = as.character(route10), 
            route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
    ) %>% 
  drop_na(route_name) %>% 
  mutate(route_number = str_sub(route_number, 6, -1))
```

Now we filter this dataframe to only show stations that serve the A
train and of this subset those that are ADA compliant:

``` r
nrow(filter(nyc_transit_distinct_tidy_df, route_name == "A"))
```

    ## [1] 60

``` r
nrow(filter(nyc_transit_distinct_tidy_df, route_name == "A", ada == TRUE))
```

    ## [1] 17

There are 60 stations serving the A train.

Of these stations 17 are ADA compliant.

## Problem 2

The following code loads the data from the Excel into a dataframe and
specifies the sheet in the Excel file and omits non-data entries. By
applying clean_names I ensure the use of reasonable variable names. Next
I omit rows that do not include dumpster-specific data (i.e., the last
row) and round the number of sports balls to the nearest integer and
convert the result to an integer variable:

``` r
mr_trash = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N550") %>%
  mutate(trash_wheel = "mister") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, 0)))
```

I repeat the same process for the Professor Trash Wheel, except that
this dataset does not contain a sport ball column, and that I transform
the year variable from numeric to character to match the mister_trash
dataset:

``` r
professor_trash = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M91") %>%
  mutate(trash_wheel = "professor") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(year = as.character(year))
```

Then I combine the two datasets:

``` r
combined_trash =
  bind_rows(mr_trash, professor_trash)
```

There are 636 observations in the combined dataset.

A list of all (key) variables dumpster, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered,
trash_wheel

The total weight of trash collected by Professor Trash Wheel is 176.08
tons.

The total number of sports balls collected by Mr. Trash Wheel in 2020 is
856.

## Problem 3

First, I clean the data in pols-month.csv: use separate() to break up
the variable mon into integer variables year, month, and day; replace
month number with month name; create a president variable taking values
gop and dem, and remove prez_dem and prez_gop; and remove the day
variable:

``` r
pols_month = 
  read_csv("./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month","day")) %>%
  mutate(month = as.integer(month),
         month = month.name[month],
         year = as.integer(year)) %>% 
  mutate(president = if_else(prez_gop == 0, "dem", "gop")) %>%
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Second, I clean the data in snp.csv using a similar process to the
above. For consistency across datasets, I arranged according to year and
month, and organized so that year and month are the leading columns:

``` r
snp = 
  read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  separate(date, into = c("year", "month","day")) %>%
  mutate(
    year = as.integer(year),
    year = ifelse(year > 2050, year - 100, year)) %>%
## Note: somehow the lubridate function converted all years older than 1959 (i.e., 58 or lower) into future dates (i.e., 2058) instead of past datest (i.e., 1958) - this formula fixed it
  mutate(month = as.integer(month),
         month = month.name[month]) %>%
  select(-day) %>% 
  relocate(year, month) %>%
  arrange(year, month)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Third, I tidy the unemployment data by switching from “wide” to “long”
format; ensuring that key variables have the same name; and ensuring
that key variables take the same values:

``` r
unemployment = 
  read_csv("./data/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  janitor::clean_names() %>%
  mutate(
    month = month.name[match(month,month.abb)],
    year = as.integer(year))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Lastly, I join the datasets by merging snp into pols, and merging
unemployment into the result.

``` r
combined_p3 = 
  left_join(pols_month, snp) %>% 
  left_join(unemployment)
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")

Quickly double-checking whether the piping works with join functions as
expected:

``` r
combined_p3_2 = left_join(pols_month, snp)
```

    ## Joining, by = c("year", "month")

``` r
combined_p3_2 = left_join(combined_p3_2, unemployment)
```

    ## Joining, by = c("year", "month")

Pols_month is a 822 rows by 9 columns dataset with a range of years of
1947, 2015 and which contains the following key variables year, month,
gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president . Snp is
a 787 rows by 3 columns dataset with a range of years of 1951, 2050 and
which contains the following key variables year, month, close.
Unemployment is a 816 rows by 3 columns dataset with a range of years of
1948, 2015 and which contains the following key variables year, month,
unemployment. By combining all three datasets into a single one called
combined_p3, which is a 822 rows by 11 columns dataset with a range of
years of 1947, 2015 and which contains the following key variables year,
month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president,
close, unemployment.
